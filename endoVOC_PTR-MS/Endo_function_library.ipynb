{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5410eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "import time\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b947d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_label(df):\n",
    "    label = df.iloc[:,1]\n",
    "    classlb = []\n",
    "    for i in label:\n",
    "        if 'H' in i:\n",
    "            classlb.append(0)\n",
    "        if 'C' in i:\n",
    "            classlb.append(1)\n",
    "    \n",
    "    classlb = np.array(classlb)\n",
    "    \n",
    "    return classlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de3d50-04fc-4f13-b0a4-c174db817489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that contain NaN in a new dataset\n",
    "def droplist(df): \n",
    "    drop_col = []\n",
    "    for col in df.columns: \n",
    "        nan = df[col].isna()\n",
    "        for i in nan: \n",
    "            if i == True:\n",
    "                drop_col.append(col)\n",
    "                break\n",
    "    df_new = df.drop(drop_col, axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58c06d-ab45-4f0a-98d3-4f404f9fdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endo_assign(df): \n",
    "    colnum_all = len(df.columns) \n",
    "    endo = df.iloc[:,2:colnum_all]\n",
    "    endo = endo.to_numpy()\n",
    "\n",
    "    return endo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a98fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(df, size):\n",
    "    \n",
    "    endo = endo_assign(df)\n",
    "    classlb = class_label(df)\n",
    "    \n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(endo, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    \n",
    "    return X_train_all, y_train_all, X_test_all, y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb77bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_clf (df, size):\n",
    "    start_time = time.time()\n",
    "    print('Time start: ', start_time)\n",
    "    result = test_train_split(df, size)\n",
    "    grid_search.fit(result[0], result[1]) #X_train_all and y_train_all\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    print('Best hyperparameters:',  grid_search.best_params_)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a961c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(df, clf, size):\n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[2]) #model accuracy on the test sets\n",
    "    print(\"MODEL ACCURACY: \", metrics.accuracy_score(result[3], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_score(df, clf, size):\n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[2]) #model accuracy on the test sets\n",
    "    print(classification_report(y_pred, result[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3402cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_fit(df, clf, size):\n",
    "    \n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[2])\n",
    "    \n",
    "    clf.fit(result[0], result[1])\n",
    "    y_pred_all = clf.predict_proba(result[2])[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(result[3], y_pred_all)\n",
    "\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03f7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot week4, 5, 6 in the same figure\n",
    "def plot_roc_allwks(df1, df2, df3, clf1, clf2, clf3, size):\n",
    "    \n",
    "    pr1 = clf_fit(df1, clf1, size)\n",
    "    pr2 = clf_fit(df2, clf2, size)\n",
    "    pr3 = clf_fit(df3, clf3, size)\n",
    "        \n",
    "    roc_auc1 = auc(pr1[0], pr1[1])\n",
    "    roc_auc2 = auc(pr2[0], pr2[1])\n",
    "    roc_auc3 = auc(pr3[0], pr3[1])\n",
    "    \n",
    "    plt.figure(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    \n",
    "    plt.plot(pr1[0], pr1[1], color='hotpink', lw=1.5, label='W4 (AUC: %0.2f)' % roc_auc1)\n",
    "    plt.plot(pr2[0], pr2[1], color='darkmagenta', lw=1.5, label='W5 (AUC: %0.2f)' % roc_auc2)\n",
    "    plt.plot(pr3[0], pr3[1], color= 'midnightblue', label='W6 (AUC: %0.2f)' % roc_auc3)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3, label='Random classifier')\n",
    "\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.xlabel('1 - Specificity', fontsize=13, labelpad=7)\n",
    "    plt.ylabel('Sensitivity', fontsize=13, labelpad=7)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(0.29, 0.4), loc='best', facecolor=\"None\", edgecolor=\"None\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac30f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_wk(df, clf, size):\n",
    "    \n",
    "    pr = clf_fit(df, clf, size)\n",
    "    roc_auc = auc(pr[0], pr[1])\n",
    "    \n",
    "    plt.figure(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    \n",
    "    plt.plot(pr[0], pr[1], color='black', lw=1.5, label='EA (AUC: %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3, label='Random classifier')\n",
    "\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.xlabel('1 - Specificity', fontsize=13, labelpad=7)\n",
    "    plt.ylabel('Sensitivity', fontsize=13, labelpad=7)\n",
    "\n",
    "    plt.legend(loc='best', facecolor=\"None\", edgecolor=\"None\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4158e-ab3b-4e2d-983d-3be5762ee116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_mz(df): \n",
    "    #feature_names: id based on which column the feature is listed\n",
    "    feature_names = [f\"{i}\" for i in range(endo_assign(df).shape[1])]\n",
    "    feature_mz = []\n",
    "    for i in feature_names:\n",
    "        feature_mz.append(df.columns[int(i)+2])\n",
    "        \n",
    "    return feature_names, feature_mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd653ee-9d41-4795-8fcb-66fafacfa06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_summary_plot(clf, df, size, max_display):\n",
    "    explainer = shap.Explainer(clf)\n",
    "    shap_values = explainer(test_train_split(df, size)[2]) #X_test\n",
    "\n",
    "    shap.summary_plot(shap_values, test_train_split(df, size)[2], max_display=max_display, feature_names=get_feature_mz(df)[1], plot_size=(6.5, 8)) #X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c896989-9e5c-455b-8290-c831441a706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(clf, df, size, head):\n",
    "    explainer = shap.Explainer(clf )\n",
    "    shap_values = explainer(test_train_split(df, size)[2]) #X_test\n",
    "    feature_names = get_feature_mz(df)[0]\n",
    "    feature_mz = get_feature_mz(df)[1]\n",
    "    \n",
    "    importance = pd.DataFrame(shap_values.values, columns = feature_names)\n",
    "    vals = np.abs(importance.values).mean(0)\n",
    "\n",
    "    shap_importance = pd.DataFrame(list(zip(feature_mz, vals)),\n",
    "                                  columns=['m/z','feature_vals'])\n",
    "    shap_importance.sort_values(by=['feature_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "    shap_head = shap_importance.head(head)\n",
    "\n",
    "    return shap_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score\n",
    "def cross_val_with_f1(classifier, X, y, n_splits=5, random_state=42):\n",
    "\n",
    "    cv = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    f1_scores = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.rc('font', family='Arial')\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), dpi=160)\n",
    "\n",
    "    for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "\n",
    "        # Skip single-class folds\n",
    "        if len(np.unique(y[test])) > 1:\n",
    "            viz = RocCurveDisplay.from_estimator(\n",
    "                classifier,\n",
    "                X[test],\n",
    "                y[test],\n",
    "                name=f\"Fold {fold}\",\n",
    "                alpha=0.4,\n",
    "                lw=1,\n",
    "                ax=ax)\n",
    "\n",
    "            # Check if AUC is valid\n",
    "            if not math.isnan(viz.roc_auc):\n",
    "                interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(viz.roc_auc)\n",
    "\n",
    "                # F1 score calculation\n",
    "                y_pred = classifier.predict(X[test])\n",
    "                f1 = f1_score(y[test], y_pred)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "    # Mean ROC Curve\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    curve_properties = {'color': 'black', 'linewidth': 1.5}\n",
    "    ax.plot(mean_fpr, mean_tpr, \n",
    "            color = \"black\",\n",
    "            lw = 1.5, \n",
    "            label= r\"Mean (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc))\n",
    "\n",
    "    ax.set_xlabel('1 - Specificity', fontsize=12)\n",
    "    ax.set_ylabel('Sensitivity', fontsize=12)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"std_auc\": std_auc,\n",
    "        \"mean_f1\": np.mean(f1_scores) if f1_scores else None,\n",
    "        \"std_f1\": np.std(f1_scores) if f1_scores else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941ac68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
