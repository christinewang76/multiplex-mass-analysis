{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5410eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b947d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_label(df):\n",
    "    label = df.iloc[:,0]\n",
    "    classlb = []\n",
    "    for i in label:\n",
    "        if 'H' in i:\n",
    "            classlb.append(0)\n",
    "        if 'E' in i:\n",
    "            classlb.append(1)\n",
    "    \n",
    "    classlb = np.array(classlb)\n",
    "    \n",
    "    return classlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228fa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ns_assign(df):\n",
    "    ns1 = df.iloc[:,1].to_numpy().reshape(-1, 1)\n",
    "    ns2 = df.iloc[:,2].to_numpy().reshape(-1, 1)\n",
    "    ns3 = df.iloc[:,3].to_numpy().reshape(-1, 1)\n",
    "    ns4 = df.iloc[:,4].to_numpy().reshape(-1, 1)\n",
    "    ns5 = df.iloc[:,5].to_numpy().reshape(-1, 1)\n",
    "    ns_all = df.iloc[:,1:6].to_numpy()\n",
    "    \n",
    "    return ns1, ns2, ns3, ns4, ns5, ns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a98fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(df, size):\n",
    "    \n",
    "    ns1 = ns_assign(df)[0]\n",
    "    ns2 = ns_assign(df)[1]\n",
    "    ns3 = ns_assign(df)[2]\n",
    "    ns4 = ns_assign(df)[3]\n",
    "    ns5 = ns_assign(df)[4]\n",
    "    ns_all = ns_assign(df)[5]\n",
    "    \n",
    "    classlb = class_label(df)\n",
    "    \n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(ns1, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(ns2, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    X_train3, X_test3, y_train3, y_test3 = train_test_split(ns3, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(ns4, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    X_train5, X_test5, y_train5, y_test5 = train_test_split(ns5, classlb, test_size=size , random_state=0, shuffle=True)\n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(ns_all, classlb, test_size=size, random_state=0, shuffle=True)\n",
    "    \n",
    "    return X_train1, y_train1, X_test1, y_test1, \\\n",
    "            X_train2, y_train2, X_test2, y_test2, \\\n",
    "            X_train3, y_train3, X_test3, y_test3, \\\n",
    "            X_train4, y_train4, X_test4, y_test4, \\\n",
    "            X_train5, y_train5, X_test5, y_test5, \\\n",
    "            X_train_all, y_train_all, X_test_all, y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb77bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_clf (df, size):\n",
    "    result = test_train_split(df, size)\n",
    "    grid_search.fit(result[20], result[21]) #X_train_all and y_train_all\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    print('Best hyperparameters:',  grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a961c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(df, clf, size):\n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[22]) #model accuracy on the test sets\n",
    "    print(\"MODEL ACCURACY: \", metrics.accuracy_score(result[23], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_score(df, clf, size):\n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[22]) #model accuracy on the test sets\n",
    "    print(classification_report(y_pred, result[23]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3402cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_fit(df, clf, size):\n",
    "    \n",
    "    result = test_train_split(df, size)\n",
    "    y_pred = clf.predict(result[22])\n",
    "    \n",
    "    clf.fit(result[0], result[1]) #fitting on the train sets\n",
    "    y_pred1 = clf.predict_proba(result[2])[:, 1]\n",
    "    fpr1, tpr1, thresholds = roc_curve(result[3], y_pred1)\n",
    "\n",
    "    clf.fit(result[4], result[5])\n",
    "    y_pred2 = clf.predict_proba(result[6])[:, 1]\n",
    "    fpr2, tpr2, thresholds = roc_curve(result[7], y_pred2)\n",
    "\n",
    "    clf.fit(result[8], result[9])\n",
    "    y_pred3 = clf.predict_proba(result[10])[:, 1]\n",
    "    fpr3, tpr3, thresholds = roc_curve(result[11], y_pred3)\n",
    "\n",
    "    clf.fit(result[12], result[13])\n",
    "    y_pred4 = clf.predict_proba(result[14])[:, 1]\n",
    "    fpr4, tpr4, thresholds = roc_curve(result[15], y_pred4)\n",
    "\n",
    "    clf.fit(result[16], result[17])\n",
    "    y_pred5 = clf.predict_proba(result[18])[:, 1]\n",
    "    fpr5, tpr5, thresholds = roc_curve(result[19], y_pred5)\n",
    "\n",
    "    clf.fit(result[20], result[21])\n",
    "    y_pred_all = clf.predict_proba(result[22])[:, 1]\n",
    "    fpr_all, tpr_all, thresholds = roc_curve(result[23], y_pred_all)\n",
    "\n",
    "    return fpr1, tpr1, fpr2, tpr2, fpr3, tpr3, fpr4, tpr4, fpr5, tpr5, fpr_all, tpr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "628ea948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_allns(df, clf, size):\n",
    "    \n",
    "    pr = clf_fit(df, clf, size)\n",
    "        \n",
    "    roc_auc1 = auc(pr[0], pr[1])\n",
    "    roc_auc2 = auc(pr[2], pr[3])\n",
    "    roc_auc3 = auc(pr[4], pr[5])\n",
    "    roc_auc4 = auc(pr[6], pr[7])\n",
    "    roc_auc5 = auc(pr[8], pr[9])\n",
    "    roc_auc_all = auc(pr[10], pr[11])\n",
    "    \n",
    "    #vABN1: PP01-HFA1 (col1, E1), vABN2: PP13-HFA3 (col4, E2), vABN2: PP12-d5eth (col2, E3), \n",
    "    #vABN3: PP10-d7isop (col3, E4), #vABN5: PP04-d3but (col5, E5)\n",
    "    plt.figure(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    plt.plot(pr[0], pr[1], color='red', lw=1.5, label='PP01-HFA1 (AUC: %0.2f)' % roc_auc1)\n",
    "    plt.plot(pr[8], pr[9], color='saddlebrown', lw=1.5, label='PP13-HFA3 (AUC: %0.2f)' % roc_auc4)\n",
    "    plt.plot(pr[2], pr[3], color='gold', lw=1.5, label='PP10-d7isop (AUC: %0.2f)' % roc_auc2)\n",
    "    plt.plot(pr[4], pr[5], color='blue', lw=1.5, label='PP12-d5eth (AUC: %0.2f)' % roc_auc3)\n",
    "    plt.plot(pr[6], pr[7], color='green', lw=1.5, label='PP09-d3but (AUC: %0.2f)' % roc_auc5)\n",
    "\n",
    "    plt.plot(pr[10], pr[11], color='black', lw=1.5, label='Multiplex (AUC = %0.2f)' % roc_auc_all)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.2, lw=1.5, label='Random classifier')\n",
    "\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel('1 - Specificity', fontsize=15)\n",
    "    plt.ylabel('Sensitivity', fontsize=15)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 0.9), loc='upper left', edgecolor=\"None\", fontsize=13)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03f7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot week4, 5, 6 in the same figure\n",
    "def plot_roc_allwks(df1, df2, df3, clf1, clf2, clf3, size):\n",
    "    \n",
    "    pr1 = clf_fit(df1, clf1, size)\n",
    "    pr2 = clf_fit(df2, clf2, size)\n",
    "    pr3 = clf_fit(df3, clf3, size)\n",
    "        \n",
    "    roc_auc1 = auc(pr1[10], pr1[11])\n",
    "    roc_auc2 = auc(pr2[10], pr2[11])\n",
    "    roc_auc3 = auc(pr3[10], pr3[11])\n",
    "    \n",
    "    plt.figure(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    \n",
    "    plt.plot(pr1[10], pr1[11], color='hotpink', lw=1.5, label='W4 (AUC: %0.2f)' % roc_auc1)\n",
    "    plt.plot(pr2[10], pr2[11], color='darkmagenta', lw=1.5, label='W5 (AUC: %0.2f)' % roc_auc2)\n",
    "    plt.plot(pr3[10], pr3[11], color= 'midnightblue', label='W6 (AUC: %0.2f)' % roc_auc3)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3, label='Random classifier')\n",
    "\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.xlabel('1 - Specificity', fontsize=13, labelpad=7)\n",
    "    plt.ylabel('Sensitivity', fontsize=13, labelpad=7)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(0.29, 0.4), loc='best', facecolor=\"None\", edgecolor=\"None\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac30f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_wk(df, clf, size):\n",
    "    \n",
    "    pr = clf_fit(df, clf, size)\n",
    "    roc_auc = auc(pr[10], pr[11])\n",
    "    \n",
    "    plt.figure(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    \n",
    "    plt.plot(pr[10], pr[11], color='black', lw=1.5, label='Eml4-Alk (AUC: %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3, label='Random classifier')\n",
    "\n",
    "    plt.xticks(fontsize=11)\n",
    "    plt.yticks(fontsize=11)\n",
    "    plt.xlabel('1 - Specificity', fontsize=13, labelpad=7)\n",
    "    plt.ylabel('Sensitivity', fontsize=13, labelpad=7)\n",
    "\n",
    "    plt.legend(loc='best', facecolor=\"None\", edgecolor=\"None\", fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80ecef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred): \n",
    "    fig, ax = plt.subplots(figsize=(3, 3),dpi = 160)\n",
    "    plt.rc('font', family='Arial')\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=['Healthy', 'Cancer'],cmap=plt.cm.Reds, ax=ax)\n",
    "    plt.rcParams.update({'font.size': 11})\n",
    "    \n",
    "    label_font = {'size':'12'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted labels', fontdict=label_font, labelpad=10);\n",
    "    ax.set_ylabel('True labels', fontdict=label_font, labelpad=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score\n",
    "def cross_val_with_f1(classifier, X, y, n_splits=5, random_state=42):\n",
    "\n",
    "    cv = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    f1_scores = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.rc('font', family='Arial')\n",
    "    fig, ax = plt.subplots(figsize=(4, 4), dpi=160)\n",
    "\n",
    "    for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "\n",
    "        # Skip single-class folds\n",
    "        if len(np.unique(y[test])) > 1:\n",
    "            viz = RocCurveDisplay.from_estimator(\n",
    "                classifier,\n",
    "                X[test],\n",
    "                y[test],\n",
    "                name=f\"Fold {fold}\",\n",
    "                alpha=0.4,\n",
    "                lw=1,\n",
    "                ax=ax)\n",
    "\n",
    "            # Check if AUC is valid\n",
    "            if not math.isnan(viz.roc_auc):\n",
    "                interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "                interp_tpr[0] = 0.0\n",
    "                tprs.append(interp_tpr)\n",
    "                aucs.append(viz.roc_auc)\n",
    "\n",
    "                # F1 score calculation\n",
    "                y_pred = classifier.predict(X[test])\n",
    "                f1 = f1_score(y[test], y_pred)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "    # Mean ROC Curve\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"black\",\n",
    "        label=r\"Mean (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=1.5,\n",
    "        alpha=1.0)\n",
    "\n",
    "    ax.set_xlabel('1 - Specificity', fontsize=12)\n",
    "    ax.set_ylabel('Sensitivity', fontsize=12)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"std_auc\": std_auc,\n",
    "        \"mean_f1\": np.mean(f1_scores) if f1_scores else None,\n",
    "        \"std_f1\": np.std(f1_scores) if f1_scores else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941ac68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
